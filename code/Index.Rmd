---
title: |
  | Student Academic Risk Prediction: 
  | Index
author: "Getty, Turner, Nickols, & Bisgin PHD"
date: "`r Sys.Date()`"
output:
  html_document: 
    css: "style.css"
    includes:
      in_header: logo.html
  pdf_document: default
 
---
<center>
# Introduction

This project aims to predict student academic risk using various machine learning models. The data used in this project is from the University of Michigan-Flint. The data includes information about students' demographics, academic performance, and other relevant information. The goal is to predict whether a student is at risk of academic failure based on the available data.

# Dependent Variable (DV)

Satisfactory/Unsatisfactory Defined

Satisfactory = 1 = "Passing Course with D or Better"

Un-Satisfactory = 0 = "D- and lower, Drop/Withdrawal, and Incomplete"

# Data Exploration

-   [Data Exploration](StudentAcademicRiskDescStats_032024.html)

# Machine Learning Models Exploration

-   [Decision Tree Classifier](StudentAcademicRiskDT_032024.html)
-   [Random Forest Classifier](StudentAcademicRiskRF_032024.html)
-   [Support Vector Machines](StudentAcademicRiskSVM_032024.html)
-   [K-Nearest Neighbors](StudentAcademicRiskKNN_032024.html)
-   [Naive Bayes](StudentAcademicRiskNB_032024.html)

In this project, we explored various machine learning models to predict student academic risk. We used data from the University of Michigan-Flint to train and test the models. The results show that the Random Forest model performed the best in terms of accuracy and precision using the top 5 features when compared.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{python py setup, include=FALSE}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
```

```{python read data and build data frames, include=FALSE}
# Read in the data and turn low_memory off to prevent mixed data types
df = pd.read_csv("../Data/CSC_587_ProjectData_032324.csv",low_memory=False)
# print(df_head.to_markdown(tablefmt="grid"))
```

```{python Cleaning Data, include=FALSE}
# clean the data
from pandas.api.types import is_numeric_dtype
from textblob import TextBlob

def clean_data(data):
    df_columns = df.columns.values.tolist()
    for column in df_columns:
        percent_null = df[column].isnull().sum() / len(df)
        if(is_numeric_dtype(df[column])):
            mean_value = df[column].mean().round(2)
            if(percent_null > 0):
                df[column] = df[column].fillna(mean_value)
        elif('SAT_' in column or 'ACT_' in column):
            mean_value = df[column].mean().round(0)
            if(percent_null > 0):
                df[column] = df[column].fillna(mean_value)
        elif('COMMENT' in column):
            df[column] = df[column].fillna('neutral data')
            df[column] = df[column].str.replace(' +', ' ') # remove extra spaces
            df[column] = df[column].str.lower()
            df[column] = df[column].str.replace('\n','')
            df[column] = df[column].str.replace('\t','')
            df[column] = df[column].str.replace('\r','')
            df[column] = df[column].str.replace(r'[^\w\s]+', '')
    return df

df = clean_data(df)
print(df.head())
```
```{python sentiment Analysis, include=FALSE}
# sentiment analysis function
def sa(data):
    def getSubjectivity(text):
        return TextBlob(text).sentiment.subjectivity
    def getPolarity(text):
        return TextBlob(text).sentiment.polarity
    data['Subjectivity'] = data['ASSIGN_COMMENT'].apply(getSubjectivity)
    data['Polarity'] = data['ASSIGN_COMMENT'].apply(getPolarity)
    def getAnalysis(score):
        if score < 0:
            return 'Negative'
        elif score == 0:
            return 'Neutral'
        else:
            return 'Positive'
    def getAnalysisCode(score):
        if score < 0:
            return 1
        elif score == 2:
            return 3
        else:
            return 1
    data['Analysis'] = data['Polarity'].apply(getAnalysis)
    data['AnalysisCode_cat'] = data['Polarity'].apply(getAnalysisCode)
    return data

sadf = sa(df)
# print negative comments from data
print("Sentament Analysis")
print(sadf[sadf['Analysis'] == 'Negative'])
# print file to csv
sadf.to_csv('sentiment_analysis.csv', index=False)
```

```{python Variables, include=FALSE}
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestClassifier

dep = sadf.SATISFACTORY_UNSATISFACTORY_BIN

model_features = ['GPA_MOD', 'HSCH_GPA', 'PCOL_GPA', 'UMF_OVERALL_GPA',
                  'SAT_TOTAL_COMBINED', 'ACT_COMPOSITE', 'AGE', 'GENDER_CAT',
                  'REPORT_ETHNICITY_CODE', 'CLASS_ORD', 'HOLD_1_CAT', 'TYPE_CAT',
                  'ASSIGN_SCORE', 'STUDENT_TYPE_CAT', 'ONLINE_ONLY_BIN',
                  'PRIMARY_LEVEL_CAT', 'FLINT_PROMISE_BIN', 'PARENT_EDU_CAT',
                  'AnalysisCode_cat']
ind = sadf[model_features]
```

```{python Train Test Split, include=FALSE}
# Hard coding rnd_tts to:
rnd_tts = 2
train_ind, test_ind, train_dep, test_dep = train_test_split(ind, dep, random_state = rnd_tts)
model = RandomForestClassifier()
model.fit(train_ind,train_dep)
predictions = model.predict(test_ind).round()
accuracy = model.score(test_ind, test_dep)
accuracy = round(accuracy, 2)
mea = mean_absolute_error(test_dep, predictions)
mea = mea.round(2)
```

```{python Features Importance List, include=FALSE}
feat_dict = {}
for col, val in sorted(zip(ind.columns, model.feature_importances_),key=lambda x:x[1],reverse=True):
  feat_dict[col]=val
feat_df = pd.DataFrame({'Feature':feat_dict.keys(),'Importance':feat_dict.values()})
feat_df
```

```{python Feature Importance Viz, echo=FALSE}
def f_importances(coef, names, top=-1):
    imp = coef
    imp, names = zip(*sorted(list(zip(imp, names))))

    # Show all features
    if top == -1:
        top = len(names)

    plt.barh(range(top), imp[::-1][0:top], align='center')
    plt.yticks(range(top), names[::-1][0:top])
    plt.show()
    
f_importances(abs(model.feature_importances_), model_features, top = 5)
```

```{python results, echo=FALSE}
# build dataframe of the results
import pandas as pd
results = pd.DataFrame({'Model': ['Decision Tree Classifier', 'Random Forest Classifier', 'Support Vector Machines', 'K-Nearest Neighbors', 'NaÃ¯ve Bayes'],
                        'Accuracy': [0.95, 0.95, 0.9, 0.94, 0.85],
                        'Sensitivity': [0.98, 0.97, 0.99, 0.97, 0.86],
                        'Specificity': [0.77, 0.79, 0.27, 0.8, 0.72],
                        'AUC': [0.89, 0.98, 0.9, 0.98, 0.87]})

print(results.to_markdown(index=False, tablefmt="grid"), '\n')
```

[![Decision Tree](RFTree.png){width="701"}](StudentAcademicRiskRF_032024.html)
# Conclusion
</center>



